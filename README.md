# CNN on MNIST with BatchNorm, Grad-CAM, and FGSM

**Analyzing CNN performance and interpretability improvements using Batch Normalization, Grad-CAM visualization, and FGSM adversarial attacks on MNIST.**

---

## Introduction

This repository demonstrates how Batch Normalization stabilizes and enhances CNN performance, visualizes CNN predictions using Grad-CAM for interpretability, and evaluates CNN robustness through adversarial examples generated by the Fast Gradient Sign Method (FGSM). Experiments combine these techniques to showcase the interactions between interpretability and robustness.

---

## Batch Normalization Analysis

![Accuracy comparison over 50 runs](experiments/batch_norm/accuracy_compare_50runs.png)

- **Purpose:** Evaluating the impact of Batch Normalization on CNN training stability and accuracy.
    
- **Experiment:** CNN training repeated over 50 runs with and without BatchNorm layers.
    
- **Insights:** Batch Normalization significantly stabilizes training and improves accuracy consistency across runs.
    

---

## Grad-CAM and FGSM Analysis

![Grad-CAM visualizations on FGSM adversarial examples](experiments/gradcam_and_fgsm/gradcam_and_fgsm.png)

### Grad-CAM

- **Objective:** Visualize CNN predictions to interpret learned features.
    
- **Method:** Grad-CAM generates heatmaps highlighting regions influencing CNN decisions.
    

### FGSM Adversarial Attacks

- **Objective:** Assess CNN robustness by generating minimally perturbed images that deceive the model.
    
- **Method:** FGSM creates adversarial examples by slightly altering input pixels based on model gradients.
    

### Grad-CAM on FGSM Images

- **Objective:** Combine FGSM and Grad-CAM to analyze model focus under adversarial conditions.
    
- **Insights:** Heatmaps reveal how CNN attention shifts when processing adversarially perturbed images, illustrating vulnerabilities in feature reliance.
    

---

## Usage Instructions

### Requirements

- Python 3.x
    
- PyTorch
    
- Torchvision
    
- NumPy
    
- Matplotlib
    

Install dependencies via:

```bash
pip install torch torchvision numpy matplotlib
```

### BatchNorm Experiment (`run_bn_statistic.py`)

```bash
python experiments/batch_norm/run_bn_statistic.py --runs 50 --epochs 10 --batch-size 64
```

- `--runs`: Number of repetitions (default: 50)
    
- `--epochs`: Training epochs per run
    
- `--batch-size`: Size of training batches
    

### Grad-CAM & FGSM Visualization (`gradcam_and_fgsm.py`)

```bash
python experiments/gradcam_and_fgsm/gradcam_and_fgsm.py --model-path path/to/model.pt --epsilons 0 0.05 0.1 0.15 0.2 0.25 --samples 8
```

- `--model-path`: Path to trained CNN model (`.pt` file)
    
- `--epsilons`: FGSM perturbation strengths to evaluate
    
- `--samples`: Number of sample images to visualize (default: 8)
    

---

## Folder Structure

```
.
├── src/
│   ├── dataloaders.py        # Data loading utilities
│   ├── models.py             # CNN models definitions
│   └── train_utils.py        # Training utilities and helper functions
│
└── experiments/
    ├── batch_norm/
    │   ├── run_bn_statistic.py       # Runs BatchNorm experiments
    │   ├── cnn_base.pt               # Trained CNN without BatchNorm
    │   ├── cnn_bn.pt                 # Trained CNN with BatchNorm
    │   └── accuracy_compare_50runs.png # BatchNorm accuracy comparison
    │
    └── gradcam_and_fgsm/
        ├── gradcam_and_fgsm.py       # Grad-CAM visualizations on FGSM examples
        └── gradcam_and_fgsm.png      # Visualization results
```

---

## References

- **Grad-CAM:** Selvaraju et al., "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization" ([paper](https://arxiv.org/abs/1610.02391))
    
- **FGSM:** Goodfellow et al., "Explaining and Harnessing Adversarial Examples" ([paper](https://arxiv.org/abs/1412.6572))
    
- **Batch Normalization:** Ioffe & Szegedy, "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift" ([paper](https://arxiv.org/abs/1502.03167))